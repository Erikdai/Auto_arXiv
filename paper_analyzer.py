#!/usr/bin/env python3
"""
è®ºæ–‡åˆ†æå·¥å…· - ä½¿ç”¨Groq LLMåˆ†ææ•°æ®åº“ä¸­çš„è®ºæ–‡
"""
import psycopg2
from langchain_groq import ChatGroq
from config import DB_CONFIG, GROQ_CONFIG
import json

class PaperAnalyzer:
    def __init__(self):
        # æ£€æŸ¥APIå¯†é’¥
        if not GROQ_CONFIG['api_key']:
            raise ValueError("âŒ Groq APIå¯†é’¥æœªé…ç½®ï¼è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®GROQ_API_KEY")
        
        # åˆå§‹åŒ–LLM - å¯¹Qwenæ¨¡å‹å…³é—­æ¨ç†è¿‡ç¨‹
        if 'qwen' in GROQ_CONFIG['model'].lower():
            self.llm = ChatGroq(
                model=GROQ_CONFIG['model'],
                temperature=0,
                max_tokens=1000,
                timeout=60,
                max_retries=3,
                api_key=GROQ_CONFIG['api_key'],
                extra_body={"reasoning_effort": "none"}
            )
        else:
            self.llm = ChatGroq(
                model=GROQ_CONFIG['model'],
                temperature=0,
                max_tokens=1000,
                timeout=60,
                max_retries=3,
                api_key=GROQ_CONFIG['api_key']
            )
        
        # æ•°æ®åº“è¿æ¥
        self.connection = psycopg2.connect(
            host=DB_CONFIG['host'],
            database=DB_CONFIG['database'],
            user=DB_CONFIG['user'],
            password=DB_CONFIG['password'],
            port=DB_CONFIG['port']
        )
        self.cursor = self.connection.cursor()

    def generate_description(self, title: str, abstract: str) -> str:
        """ä¸ºè®ºæ–‡ç”Ÿæˆéå¸¸ç®€çŸ­çš„ä¸€å¥è¯æ¦‚æ‹¬ï¼Œä¸¥æ ¼é™åˆ¶åœ¨150å­—ç¬¦å†…"""
        prompt = f"""Write ONE very short sentence summarizing this paper in 150 characters or less.

REQUIREMENTS:
- ONE simple sentence ending with period
- Maximum 150 characters total
- Very concise - just the key method and main contribution
- No unnecessary details

EXAMPLES:
"Uses multi-agent RL for task allocation."
"Proposes BERT variant for sentiment analysis."
"Introduces GNN for protein folding prediction."

Title: {title}
Abstract: {abstract}

Short summary (â‰¤150 chars):"""

        try:
            response = self.llm.invoke(prompt)
            description = response.content.strip()
            # æ¸…ç†å¼•å·å’Œå¤šä½™å­—ç¬¦ï¼ŒåŒ…æ‹¬å­—ç¬¦è®¡æ•°ä¿¡æ¯
            description = description.replace('"', '').replace("'", "").strip()
            # ç§»é™¤å¯èƒ½çš„å­—ç¬¦è®¡æ•°ä¿¡æ¯
            if "chars)" in description:
                description = description.split("(")[0].strip()
            if description.endswith("."):
                description = description[:-1].strip() + "."
            # ä¸¥æ ¼æ§åˆ¶æè¿°é•¿åº¦ï¼Œç¡®ä¿æ¨æ–‡ä¸ä¼šè¶…é™
            # æœ€å¤§å®‰å…¨æè¿°é•¿åº¦ï¼š280 - 32(é“¾æ¥) - 4(æ¢è¡Œ) - 20(æœ€å°æ ‡é¢˜) - 3(çœç•¥å·) = 221å­—ç¬¦
            # ä¸ºäº†æ›´å®‰å…¨ï¼Œé™åˆ¶åœ¨200å­—ç¬¦ä»¥å†…
            max_safe_length = 200
            
            if len(description) > max_safe_length:
                # æˆªæ–­åˆ°å®‰å…¨é•¿åº¦ï¼Œç¡®ä¿ä»¥å¥å·ç»“å°¾
                print(f"Warning: Description too long ({len(description)} chars), truncating to {max_safe_length}: {description}")
                description = description[:max_safe_length-1] + "."
                
            return description
        except Exception as e:
            # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œè¿”å›é»˜è®¤æè¿°ï¼ˆä¹Ÿè¦æ§åˆ¶é•¿åº¦ï¼‰
            return "Novel AI agent approach solving key challenges."

    def generate_detailed_analysis(self, title: str, abstract: str) -> str:
        """ä¸ºè®ºæ–‡ç”Ÿæˆè¯¦ç»†åˆ†æï¼ˆç”¨äºTwitterçº¿ç¨‹ç¬¬äºŒæ¡æ¨æ–‡ï¼‰"""
        prompt = f"""Analyze this AI agent research paper and provide a detailed technical analysis in bullet points. Focus on:
- What specific methods/techniques are used
- What problems it solves
- Key contributions or innovations
- Performance improvements or results

Keep it concise but informative, max 250 characters total. Use bullet points with â€¢ symbol.

Title: {title}
Abstract: {abstract}

Analysis:"""

        try:
            response = self.llm.invoke(prompt)
            analysis = response.content.strip()
            # æ¸…ç†å¼•å·å’Œå¤šä½™å­—ç¬¦
            analysis = analysis.replace('"', '').replace("'", "").strip()
            # é™åˆ¶é•¿åº¦
            if len(analysis) > 250:
                analysis = analysis[:247] + "..."
            return analysis
        except Exception as e:
            # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œè¿”å›é»˜è®¤åˆ†æ
            return "â€¢ Novel agent architecture\nâ€¢ Solves key challenges in multi-agent coordination\nâ€¢ Achieves improved performance over baselines"

    def analyze_abstract(self, abstract: str, topic: str = "Agent Systems") -> dict:
        """åˆ†æè®ºæ–‡æ‘˜è¦ä¸Agentç³»ç»Ÿçš„ç›¸å…³æ€§"""
        prompt = f"""You are an expert AI researcher specializing in Agent systems. Analyze if this research paper is SPECIFICALLY about AI Agents, Multi-Agent Systems, or Agentic AI.

IMPORTANT: Only papers that are DIRECTLY about AI agents should get high scores. Papers that merely mention "agent" in passing or use it in non-AI contexts should get low scores.

TRUE Agent papers include:
- Multi-agent systems and coordination
- LLM agents and agentic AI
- Autonomous agents and planning
- Agent-based reasoning and decision making
- Agent frameworks and architectures
- Conversational agents and chatbots
- Agent learning and adaptation

NOT Agent papers (should get low scores):
- Papers that only mention "agent" in citations or related work
- RAG systems (unless specifically about agentic RAG)
- General LLM research without agent focus
- Role-playing or persona research
- Benchmarking that's not agent-specific
- Fine-tuning or training methods
- User agents, web agents, or software agents

Abstract: {abstract}

Please provide a structured analysis in the following JSON format:
{{
    "relevant": true/false,
    "confidence": "High/Medium/Low",
    "relevance_score": 0-10,
    "analysis": "Brief explanation of why it is or isn't a true Agent paper",
    "keywords": ["key", "agent", "words", "found"]
}}

Be STRICT in your evaluation. Only give scores 8+ for papers that are clearly and primarily about AI agents."""

        try:
            response = self.llm.invoke(prompt)
            # å°è¯•è§£æJSONå“åº”
            try:
                # æå–JSONéƒ¨åˆ†
                content = response.content.strip()
                if content.startswith('```json'):
                    content = content[7:-3]
                elif content.startswith('```'):
                    content = content[3:-3]
                
                result = json.loads(content)
                return result
            except json.JSONDecodeError:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›åŸºæœ¬ç»“æ„
                return {
                    "relevant": "yes" in response.content.lower() or "true" in response.content.lower(),
                    "confidence": "Medium",
                    "relevance_score": 5,
                    "analysis": response.content[:200] + "...",
                    "keywords": []
                }
        except Exception as e:
            return {
                "relevant": False,
                "confidence": "Low",
                "relevance_score": 0,
                "analysis": f"Error analyzing: {str(e)}",
                "keywords": []
            }

    def analyze_recent_papers(self, limit: int = 10, topic: str = "Carbon Emission"):
        """åˆ†ææœ€è¿‘çš„è®ºæ–‡"""
        print(f"ğŸ” åˆ†ææœ€è¿‘çš„ {limit} ç¯‡è®ºæ–‡ï¼Œä¸»é¢˜: {topic}")
        print("=" * 80)
        
        # è·å–æœ€è¿‘çš„è®ºæ–‡
        self.cursor.execute("""
            SELECT id, title, abstract, category, authors, url
            FROM papers 
            ORDER BY sn DESC 
            LIMIT %s;
        """, (limit,))
        
        papers = self.cursor.fetchall()
        relevant_papers = []
        
        for i, (paper_id, title, abstract, category, authors, url) in enumerate(papers, 1):
            print(f"\nğŸ“„ [{i}/{limit}] åˆ†æè®ºæ–‡: {title[:60]}...")
            
            if not abstract or len(abstract.strip()) < 50:
                print("   âš ï¸  æ‘˜è¦å¤ªçŸ­ï¼Œè·³è¿‡åˆ†æ")
                continue
            
            # åˆ†æè®ºæ–‡
            analysis = self.analyze_abstract(abstract, topic)
            
            print(f"   ğŸ¯ ç›¸å…³æ€§: {'âœ… ç›¸å…³' if analysis['relevant'] else 'âŒ ä¸ç›¸å…³'}")
            print(f"   ğŸ“Š ç½®ä¿¡åº¦: {analysis['confidence']}")
            print(f"   ğŸ”¢ ç›¸å…³æ€§è¯„åˆ†: {analysis['relevance_score']}/10")
            print(f"   ğŸ’­ åˆ†æ: {analysis['analysis'][:100]}...")
            
            if analysis['relevant'] and analysis['relevance_score'] >= 6:
                relevant_papers.append({
                    'id': paper_id,
                    'title': title,
                    'category': category,
                    'authors': authors,
                    'url': url,
                    'analysis': analysis
                })
        
        # æ€»ç»“ç›¸å…³è®ºæ–‡
        if relevant_papers:
            print(f"\nğŸ‰ æ‰¾åˆ° {len(relevant_papers)} ç¯‡ä¸ '{topic}' ç›¸å…³çš„è®ºæ–‡:")
            print("=" * 80)
            for paper in relevant_papers:
                print(f"ğŸ“‹ {paper['title']}")
                print(f"   ğŸ‘¥ ä½œè€…: {paper['authors'][:80]}...")
                print(f"   ğŸ·ï¸  åˆ†ç±»: {paper['category']}")
                print(f"   ğŸ”— é“¾æ¥: {paper['url']}")
                print(f"   ğŸ“Š è¯„åˆ†: {paper['analysis']['relevance_score']}/10")
                print()
        else:
            print(f"\nğŸ˜” æ²¡æœ‰æ‰¾åˆ°ä¸ '{topic}' é«˜åº¦ç›¸å…³çš„è®ºæ–‡")

    def analyze_by_category(self, category: str, topic: str = "Carbon Emission"):
        """æŒ‰åˆ†ç±»åˆ†æè®ºæ–‡"""
        print(f"ğŸ” åˆ†æ '{category}' åˆ†ç±»ä¸­ä¸ '{topic}' ç›¸å…³çš„è®ºæ–‡")
        print("=" * 80)
        
        self.cursor.execute("""
            SELECT id, title, abstract, authors, url
            FROM papers 
            WHERE category = %s
            ORDER BY sn DESC;
        """, (category,))
        
        papers = self.cursor.fetchall()
        
        if not papers:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ° '{category}' åˆ†ç±»çš„è®ºæ–‡")
            return
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(papers)} ç¯‡ '{category}' åˆ†ç±»çš„è®ºæ–‡")
        
        relevant_count = 0
        for paper_id, title, abstract, authors, url in papers:
            if not abstract or len(abstract.strip()) < 50:
                continue
                
            analysis = self.analyze_abstract(abstract, topic)
            
            if analysis['relevant'] and analysis['relevance_score'] >= 7:
                relevant_count += 1
                print(f"\nâœ… ç›¸å…³è®ºæ–‡ #{relevant_count}:")
                print(f"   ğŸ“‹ æ ‡é¢˜: {title}")
                print(f"   ğŸ‘¥ ä½œè€…: {authors[:80]}...")
                print(f"   ğŸ“Š è¯„åˆ†: {analysis['relevance_score']}/10")
                print(f"   ğŸ’­ åˆ†æ: {analysis['analysis'][:150]}...")
                print(f"   ğŸ”— é“¾æ¥: {url}")
        
        print(f"\nğŸ“ˆ æ€»ç»“: åœ¨ {len(papers)} ç¯‡ '{category}' è®ºæ–‡ä¸­ï¼Œæ‰¾åˆ° {relevant_count} ç¯‡ä¸ '{topic}' ç›¸å…³")

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        self.cursor.close()
        self.connection.close()

def main():
    """ä¸»å‡½æ•°"""
    try:
        analyzer = PaperAnalyzer()
        
        print("ğŸ¤– è®ºæ–‡åˆ†æå·¥å…·")
        print("é€‰æ‹©åˆ†ææ¨¡å¼:")
        print("1. åˆ†ææœ€è¿‘çš„è®ºæ–‡")
        print("2. æŒ‰åˆ†ç±»åˆ†æè®ºæ–‡")
        print("3. é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹© (1-3): ").strip()
        
        if choice == "1":
            limit = int(input("åˆ†æå¤šå°‘ç¯‡æœ€è¿‘çš„è®ºæ–‡? (é»˜è®¤10): ") or "10")
            topic = input("åˆ†æä¸»é¢˜ (é»˜è®¤: Carbon Emission): ").strip() or "Carbon Emission"
            analyzer.analyze_recent_papers(limit, topic)
            
        elif choice == "2":
            # æ˜¾ç¤ºå¯ç”¨åˆ†ç±»
            analyzer.cursor.execute("SELECT DISTINCT category FROM papers ORDER BY category;")
            categories = [row[0] for row in analyzer.cursor.fetchall()]
            print(f"å¯ç”¨åˆ†ç±»: {', '.join(categories)}")
            
            category = input("é€‰æ‹©åˆ†ç±»: ").strip()
            topic = input("åˆ†æä¸»é¢˜ (é»˜è®¤: Carbon Emission): ").strip() or "Carbon Emission"
            analyzer.analyze_by_category(category, topic)
            
        elif choice == "3":
            print("ğŸ‘‹ å†è§!")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
        
        analyzer.close()
        
    except ValueError as e:
        print(str(e))
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main()